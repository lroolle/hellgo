#+TITLE: Go Concurrency Patterns Pipelines And Cancellation
#+DATE: 2020-08-15

#+EXPORT_FILE_NAME: go-concurrency-patterns-pipelines-and-cancellation
#+HUGO_WEIGHT: auto
#+HUGO_BASE_DIR: ~/G/blog
#+HUGO_AUTO_SET_LASTMOD: t
#+HUGO_SECTION: notes
#+HUGO_CATEGORIES: notes
#+HUGO_TAGS: golang concurrency goroutine

Original Post:
#+begin_quote
-> [[https://blog.golang.org/pipelines][Go Concurrency Patterns: Pipelines and cancellation - The Go Blog]]
#+end_quote

* Go Concurrency Patterns Pipelines And Cancellation

#+begin_quote
Go's concurrency primitives make it easy to construct streaming data pipelines
that make efficient use of I/O and multiple CPUs. This article presents examples
of such pipelines, highlights subtleties that arise when operations fail, and
introduces techniques for dealing with failures cleanly.
#+end_quote


** What is a pipeline?

There's no formal definition of a pipeline in Go; it's just one of many kinds of
concurrent programs. Informally, a pipeline is a series of stages connected by
channels, where each stage is a group of goroutines running the same function.
In each stage, the goroutines

- receive values from upstream via inbound channels
- perform some function on that data, usually producing new values
- send values downstream via outbound channels

Each stage has any number of inbound and outbound channels, except the first and
last stages, which have only outbound or inbound channels, respectively. The
first stage is sometimes called the source or producer; the last stage, the sink
or consumer.

* Squaring numbers

Consider a pipeline with three stages.

The first stage, ~gen~, is a function that converts a list of integers to a
channel that emits the integers in the list. The gen function starts a goroutine
that sends the integers on the channel and closes the channel when all the
values have been sent.

The second stage, sq, receives integers from a channel and returns a channel
that emits the square of each received integer. After the inbound channel is
closed and this stage has sent all the values downstream, it closes the outbound
channel.

#+BEGIN_SRC go :exports both :imports "fmt"
func gen(nums ...int) <-chan int {
	out := make(chan int)
	go func() {
		for _, n := range nums {
			out <- n
		}
		close(out)
	}()
	return out
}

func sq(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out <- n * n
		}
		close(out)
	}()
	return out
}

func main() {
	// Set up the pipeline and consume the output.
	numlines := sq(sq(gen(2, 3, 4)))
	for n := range numlines {
		fmt.Println(n)
	}
}
#+END_SRC

#+RESULTS:
: 16
: 81
: 256

* Fan-out, fan-in

*Multiple functions* can read from the same channel until that channel is closed;
this is called ~fan-out~. This provides a way to distribute work amongst a group
of workers to parallelize CPU use and I/O.

A function can read from *multiple inputs* and proceed until all are closed by
multiplexing the input channels onto a single channel that's closed when all the
inputs are closed. This is called fan-in.

We can change our pipeline to run two instances of sq, each reading from the
same input channel. We introduce a new function, merge, to fan in the results:

#+BEGIN_SRC go :exports both :imports "fmt"
func main() {
	in := gen(2, 3)

	// Distribute the sq work across two goroutines that both read from in.
	c1 := sq(in)
	c2 := sq(in)

	// Consume the merged output from c1 and c2.
	for n := range merge(c1, c2) {
		fmt.Println(n) // 4 then 9, or 9 then 4
	}
}
#+END_SRC

The ~merge~ function converts a list of channels to a single channel by starting
a goroutine for each inbound channel that copies the values to the sole outbound
channel. Once all the output goroutines have been started, merge starts one more
goroutine to close the outbound channel after all sends on that channel are
done.

Sends on a closed channel panic, so it's important to ensure all sends are done
before calling close. The ~sync.WaitGroup~ type provides a simple way to arrange
this synchronization:

#+BEGIN_SRC go :exports both :imports "fmt"
func merge(cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int)

	// Start an output goroutine for each input channel in cs.  output
	// copies values from c to out until c is closed, then calls wg.Done.
	output := func(c <-chan int) {
		for n := range c {
			out <- n
		}
		wg.Done()
	}
	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	// Start a goroutine to close out once all the output goroutines are
	// done.  This must start after the wg.Add call.
	go func() {
		wg.Wait()
		close(out)
	}()
	return out
}
#+END_SRC

* Stopping short

There is a pattern to our pipeline functions:

- stages close their outbound channels when all the send operations are done.
- stages keep receiving values from inbound channels until those channels are closed.
 
This pattern allows each receiving stage to be written as a range loop and
ensures that all goroutines exit once all values have been successfully sent
downstream.

But in real pipelines, stages don't always receive all the inbound values.
Sometimes this is by design: the receiver may only need a subset of values to
make progress. More often, a stage exits early because an inbound value
represents an error in an earlier stage. In either case the receiver should not
have to wait for the remaining values to arrive, and we want earlier stages to
stop producing values that later stages don't need.

In our example pipeline, if a stage fails to consume all the inbound values, the
goroutines attempting to send those values will block indefinitely:

#+BEGIN_SRC go :exports both :imports "fmt"
    // Consume the first value from the output.
    out := merge(c1, c2)
    fmt.Println(<-out) // 4 or 9
    return
    // Since we didn't receive the second value from out,
    // one of the output goroutines is hung attempting to send it.
}
#+END_SRC

This is a resource leak: goroutines consume memory and runtime resources, and
heap references in goroutine stacks keep data from being garbage collected.
Goroutines are not garbage collected; they must exit on their own.

We need to arrange for the upstream stages of our pipeline to exit even when the
downstream stages fail to receive all the inbound values. One way to do this is
to change the outbound channels to have a buffer. A buffer can hold a fixed
number of values; send operations complete immediately if there's room in the
buffer:

#+BEGIN_SRC go :exports both :imports "fmt"
c := make(chan int, 2) // buffer size 2
c <- 1  // succeeds immediately
c <- 2  // succeeds immediately
c <- 3  // blocks until another goroutine does <-c and receives 1
#+END_SRC

When the number of values to be sent is known at channel creation time, a buffer
can simplify the code. For example, we can rewrite gen to copy the list of
integers into a buffered channel and avoid creating a new goroutine:

#+BEGIN_SRC go :exports both :imports "fmt"
func gen(nums ...int) <-chan int {
	out := make(chan int, len(nums))
	for _, n := range nums {
		out <- n
	}
	close(out)
	return out
}
#+END_SRC

Returning to the blocked goroutines in our pipeline, we might consider adding a
buffer to the outbound channel returned by merge:

#+BEGIN_SRC go :exports both :imports "fmt"
func merge(cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int, 1) // enough space for the unread inputs
	// ... the rest is unchanged ...
#+END_SRC

While this fixes the blocked goroutine in this program, this is bad code. The
choice of buffer size of 1 here depends on knowing the number of values merge
will receive and the number of values downstream stages will consume. This is
fragile: if we pass an additional value to gen, or if the downstream stage reads
any fewer values, we will again have blocked goroutines.

Instead, we need to provide a way for downstream stages to indicate to the
senders that they will stop accepting input.


* Explicit cancellation

When main decides to exit without receiving all the values from out, it must
tell the goroutines in the upstream stages to abandon the values they're trying
to send. It does so by sending values on a channel called done. It sends two
values since there are potentially two blocked senders:

#+BEGIN_SRC go :exports both :imports "fmt"
func main() {
	in := gen(2, 3)

	// Distribute the sq work across two goroutines that both read from in.
	c1 := sq(in)
	c2 := sq(in)

	// Consume the first value from output.
	done := make(chan struct{}, 2)
	out := merge(done, c1, c2)
	fmt.Println(<-out) // 4 or 9

	// Tell the remaining senders we're leaving.
	done <- struct{}{}
	done <- struct{}{}
}
#+END_SRC

The sending goroutines replace their send operation with a select statement that
proceeds either when the send on out happens or when they receive a value from
done. The value type of done is the empty struct because the value doesn't
matter: it is the receive event that indicates the send on out should be
abandoned. The output goroutines continue looping on their inbound channel, c,
so the upstream stages are not blocked. (We'll discuss in a moment how to allow
this loop to return early.)

#+BEGIN_SRC go :exports both :imports "fmt"
func merge(done <-chan struct{}, cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int)

	// Start an output goroutine for each input channel in cs.  output
	// copies values from c to out until c is closed or it receives a value
	// from done, then output calls wg.Done.
	output := func(c <-chan int) {
		for n := range c {
			select {
			case out <- n:
			case <-done:
			}
		}
		wg.Done()
	}
	// ... the rest is unchanged ...
}
#+END_SRC


*This approach has a problem*: /each/ downstream receiver needs to know the number
of potentially blocked upstream senders and arrange to signal those senders on
early return. Keeping track of these counts is tedious and error-prone.

We need a way to tell an unknown and unbounded number of goroutines to stop
sending their values downstream. In Go, we can do this by closing a channel,
because a receive operation on a closed channel can always proceed immediately,
yielding the element type's zero value.

-> [[https://golang.org/ref/spec#Receive_operator][golang-sepc:Receive Operator]]

This means that main can unblock all the senders simply by closing the done
channel. This close is effectively a broadcast signal to the senders. We extend
each of our pipeline functions to accept done as a parameter and arrange for the
close to happen via a defer statement, so that all return paths from main will
signal the pipeline stages to exit.

Here are the guidelines for pipeline construction:

- stages close their outbound channels when all the send operations are done.
- stages keep receiving values from inbound channels until those channels are closed or the senders are unblocked.

Pipelines unblock senders either by ensuring there's enough buffer for all the
values that are sent or by explicitly signalling senders when the receiver may
abandon the channel.
